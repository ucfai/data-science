{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "nb-title",
     "template"
    ],
    "title": "Answering the Important Question: Where's My Money? (Part 2)"
   },
   "source": [
    "<img\n",
    "    style=\"border-radius: 0.5em;\"\n",
    "    src=\"https://ucfai.org/groups/projects/fa19/loan-defaults-p2/banner.png\">\n",
    "\n",
    "<div class=\"col-12\">\n",
    "    <h1> Answering the Important Question: Where's My Money? (Part 2) </h1>\n",
    "    <hr>\n",
    "</div>\n",
    "\n",
    "<div style=\"line-height: 2em;\">\n",
    "    <p>by: \n",
    "        <a href=\"https://ucfai.org/authors/causallycausal\">@causallycausal</a> on Oct 10, 2019</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "tags": [
     "template"
    ]
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"/kaggle/input\")\n",
    "if (DATA_DIR / \"ucfai-projects-fa19-loan-defaults-p2\").exists():\n",
    "    DATA_DIR /= \"ucfai-projects-fa19-loan-defaults-p2\"\n",
    "elif DATA_DIR.exists():\n",
    "    # no-op to keep the proper data path for Kaggle\n",
    "    pass\n",
    "else:\n",
    "    # You'll need to download the data from Kaggle and place it in the `data/`\n",
    "    #   directory beside this notebook.\n",
    "    # The data should be here: https://kaggle.com/c/ucfai-projects-fa19-loan-defaults-p2/data\n",
    "    DATA_DIR = Path(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "train = pd.read_csv(DATA_DIR / \"ucfai-dsg-fa19-default/train.csv\")\n",
    "test = pd.read_csv(DATA_DIR / \"ucfai-dsg-fa19-default/test.csv\")\n",
    "ID_test = test['id']\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "train['GOOD_STANDING'].value_counts()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "# So there are 9x as many good loans as bad (naturally, any reputable lender would avoid bad loans)\n",
    "# This is problomatic, because most models will notice that most features are associated with good loans\n",
    "# Therefore, they will most likely just predict all good loans. Why is this a problem?\n",
    "\n",
    "# The score for this comp is an AUC ROC metric. In an oversimplified sense, this score is based on both\n",
    "# how precise your positives are AND your negatives\n",
    "# If you guess on either of them, you should expect the lowest score (0.5)\n",
    "\n",
    "# There are almost 1 million examples, it is safe to undersample\n",
    "# Undersampling is basically where we only use a subset of the training data so that our good loans/bad loans are equal\n",
    "# The simple solution to this is just to randomly choose good loans to use until we are equal to bad loans\n",
    "# Here is how we are going to undersample\n",
    "import numpy as np\n",
    "\n",
    "# Give me the -length - of the subset of -train- made up of entries with GOOD_STANDING == 0 \n",
    "# In otherwords, how many bad loans are there?\n",
    "bad_standing_len = len(train[train[\"GOOD_STANDING\"] == 0])\n",
    "\n",
    "# Give me the index of the subset of train where good_standing == 1 \n",
    "# In otherwords, give me the index of all the good loans\n",
    "good_standing_index = train[train['GOOD_STANDING'] == 1].index\n",
    "\n",
    "# Randomly choose indices of good loans equal to the number of bad loans\n",
    "random_index = np.random.choice(good_standing_index, bad_standing_len, replace=False)\n",
    "\n",
    "# Give me the index of all the bad loans in train\n",
    "bad_standing_index = train[train['GOOD_STANDING'] == 0].index\n",
    "\n",
    "# Concatonate the indices of bad loans, and our randomly sampled good loans\n",
    "under_sample_index = np.concatenate([bad_standing_index, random_index])\n",
    "\n",
    "# Create a new pandas dataframe made only of these indices \n",
    "under_sample = train.loc[under_sample_index]\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "# Make sure it works, and make this undersampled dataframe our train\n",
    "train['GOOD_STANDING'].value_counts()\n",
    "under_sample['GOOD_STANDING'].value_counts()\n",
    "train = under_sample\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "# As we did in Titanic, lets concatonate train and test\n",
    "train.head()\n",
    "train_len = len(train)\n",
    "dataset =  pd.concat(objs=[train, test], axis=0).reset_index(drop=True)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "dataset = dataset.fillna(np.nan)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "len(dataset.index)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "# There are a lot of columns and a lot of nulls, so I'm going to just delete features that have more than 20% of the data missing and go from there\n",
    "\n",
    "null_list = dataset.isnull().sum()\n",
    "for column, missing_num in null_list.iteritems():\n",
    "    if column != \"GOOD_STANDING\":\n",
    "        if missing_num / len(dataset.index) > 0.2:\n",
    "            dataset = dataset.drop([column], axis = 1)\n",
    "dataset.isnull().sum()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "# Since \"sub grade\" exists, grade is kind of redundant, let's just get rid of grade\n",
    "dataset.drop(['grade'], axis=1, inplace=True)\n",
    "\n",
    "# We're also going to remove issue date because, as we discussed last week, the issue date\n",
    "# between the train and the test is unbalanced. Therefore, there is likely not much to learn from it\n",
    "dataset.drop(['issue_d'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# I'm also going to remove employee title. This might seem problamatic, but consider two things\n",
    "# We already have annual income, really how much more info can we gloss from this?\n",
    "# If we have to turn these into dummy variables, as we tend to do, there are a LOT of different titles, they will be sparse\n",
    "dataset.drop(['emp_title'], axis=1, inplace=True)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "# Under most circumstances, you want to go through and replace nulls intelligently, but to give you an idea on how to efficiently clean\n",
    "# this dataset, let's try replacing all continious values with the mean, and all categorical values with the mode\n",
    "\n",
    "number_set = set(dataset._get_numeric_data().columns)\n",
    "for i,j in dataset.iteritems():\n",
    "    print(\"Now handeling\", i)\n",
    "    # Let's break this down (it was also used in titanic)\n",
    "    # For each column in the dataset, take the subset of that column made up of null entries for that column\n",
    "    # Then, take that subset's indices and transform it into a list\n",
    "    NaN_index = list(dataset[i][dataset[i].isnull()].index)\n",
    "    # Skip the target variable obviously\n",
    "    if (i == 'GOOD_STANDING'):\n",
    "        continue\n",
    "    if i in number_set:\n",
    "        # If we are dealing with numerial values, take the median\n",
    "        med = dataset[i].mean()\n",
    "        for x in NaN_index:\n",
    "            #print(\"did I get here\")\n",
    "            dataset[i].iloc[x] = med\n",
    "    else:\n",
    "        # Otherwise, just take the most frequent categorical value \n",
    "        mode = dataset[i].value_counts().idxmax()\n",
    "        for x in NaN_index:\n",
    "           # print(\"what about here\")\n",
    "            dataset[i].iloc[x] = mode\n",
    "            \n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "# We're going to drop a couple categorical values that have way to many possible values\n",
    "# There are certainly ways you can utilize this, expecially the dates, but for the time being we will remove them\n",
    "# If there are too many possible values, get_dummies creates too many new columns\n",
    "dataset = dataset.drop(['earliest_cr_line', 'last_credit_pull_d', 'last_pymnt_d', 'addr_state', 'title'], axis=1)\n",
    "\n",
    "categorical_features = list(set(dataset.columns) - set(dataset._get_numeric_data().columns))\n",
    "\n",
    "print(categorical_features)\n",
    "dataset = pd.get_dummies(dataset, columns=categorical_features)\n",
    "dataset.head()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "dataset.head()\n",
    "dataset.isnull().sum()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "# Separate train and test\n",
    "train = dataset[:train_len]\n",
    "test = dataset[train_len:]\n",
    "# Drop the good standing from test (which should all be empty)\n",
    "test.drop(labels=[\"GOOD_STANDING\"],axis = 1,inplace=True)\n",
    "\n",
    "# Make sure they are ints\n",
    "train[\"GOOD_STANDING\"] = train[\"GOOD_STANDING\"].astype(int)\n",
    "\n",
    "Y_train = train[\"GOOD_STANDING\"]\n",
    "\n",
    "X_train = train.drop(labels = [\"GOOD_STANDING\"],axis = 1)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "# Let's jus tuse a basic random forest\n",
    "RF = RandomForestClassifier()\n",
    "RF.fit(X_train, Y_train)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "test_standing = pd.Series(RF.predict(test), name=\"GOOD_STANDING\")\n",
    "\n",
    "results = pd.concat([ID_test,test_standing],axis=1)\n",
    "\n",
    "results.to_csv(\"GradePrediction.csv\",index=False)\n",
    "### END SOLUTION"
   ]
  }
 ],
 "metadata": {
  "autobot": {
   "abstract": "We continue our deep dive into the wonderful world of loan defaults. Does the loan grading of creditors line up with what reality shows? Use machine learning to find out!",
   "authors": [
    "causallycausal"
   ],
   "date": "2019-10-10T17:30:00",
   "group": "projects",
   "semester": "fa19",
   "tags": [
    "machine learning",
    "data science",
    "finance",
    "statistics"
   ],
   "title": "Answering the Important Question: Where's My Money? (Part 2)"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
